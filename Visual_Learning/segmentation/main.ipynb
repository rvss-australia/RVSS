{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config CoLab Environment\n",
    "\n",
    "Make sure this script is opened from your own google drive folder, rather than directly opened from Github. This is crucial for saving your code for later use during the workshop. If you have not done it,  uncomment and run the cell below to clone the RVSS 2022 Github to your Google Drive, quit this Colab session and reopen it from your own google drive https://drive.google.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# %cd / content/drive/MyDrive/\n",
    "# if not os.path.exists('RVSS2022'):\n",
    "#   !git clone https://github.com/Tobias-Fischer/RVSS2022\n",
    "# else:\n",
    "#   %cd / content/drive/MyDrive/RVSS2022\n",
    "#   !git pull\n",
    "# %cd / content/drive/MyDrive/RVSS2022/Visual_Learning/segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "%cd /content/drive/MyDrive/RVSS2022/Visual_Learning/segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train The Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from segmenter import Segmenter\n",
    "import utils.cmd_printer as cmd_printer\n",
    "from trainer import Trainer\n",
    "from args import args\n",
    "from models import Res18Baseline\n",
    "from models import Res18Skip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train The Face Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imdb import FaceIMDB\n",
    "\n",
    "# args\n",
    "args.dataset_dir = 'datasets/faces'\n",
    "args.weights_dir = 'weights/face_baseline'\n",
    "args.n_classes = 2\n",
    "args.batch_size = 32\n",
    "# print args\n",
    "cmd_printer.divider(text=\"Hyper-parameters\", line_max=60)\n",
    "for arg in vars(args):\n",
    "    print(f\"   {arg}: {getattr(args, arg)}\")\n",
    "cmd_printer.divider(line_max=60)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=FaceIMDB(args.dataset_dir, mode='train'),\n",
    "                          batch_size=args.batch_size, shuffle=True,\n",
    "                          num_workers=4, drop_last=True)\n",
    "\n",
    "eval_loader = DataLoader(dataset=FaceIMDB(args.dataset_dir, mode='eval'),\n",
    "                         batch_size=args.batch_size, shuffle=False,\n",
    "                         num_workers=4, drop_last=False)\n",
    "   \n",
    "if args.model == 'res18_baseline':\n",
    "    model = Res18Baseline(args)\n",
    "elif args.model == 'res18_skip':\n",
    "    model = Res18Skip(args)\n",
    "trainer = Trainer(args)\n",
    "trainer.fit(model, train_loader, eval_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Face Segmentation\n",
    "### 'ckpt' represents checkpoint.\n",
    "\n",
    "You can set `ckpt = ''` to test if your network architecture is implemented correctly.\n",
    "\n",
    "Later on, you can set `ckpt = <path_to_weight_file>` to inspect the network outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt = ''\n",
    "ckpt = 'weights/face_baseline/model.best.pth'\n",
    "model = 'res18_baseline'\n",
    "# ckpt = 'res18_skip_weights.pth'\n",
    "# model = 'res18_skip'\n",
    "segmenter = Segmenter(ckpt, use_gpu=False, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"test_images/faces\"\n",
    "pred_dir = os.path.join(test_dir, model+'_output')\n",
    "os.makedirs(pred_dir, exist_ok=True)\n",
    "all_test_images = [file for file in os.listdir(\n",
    "    test_dir) if file.endswith('.jpg')]\n",
    "for image_name in all_test_images:\n",
    "    np_img = np.array(Image.open(os.path.join(test_dir, image_name)))\n",
    "    pred, colour_map = segmenter.segment_single_image(\n",
    "        np_img, resize_to=(256, 256), labels=['hair', 'face', 'bg'])\n",
    "    title = [\"Input\", \"Prediction\"]\n",
    "    pics = [np_img, colour_map]\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
    "    axs[0].imshow(pics[0], interpolation='nearest')\n",
    "    axs[0].set_title(title[0])\n",
    "    axs[1].imshow(pics[1], interpolation='nearest')\n",
    "    axs[1].set_title(title[1])\n",
    "    axs[0].axis('off')\n",
    "    axs[1].axis('off')\n",
    "    path = os.path.join(pred_dir, image_name)\n",
    "    plt.savefig(os.path.join(pred_dir, image_name[:-4]+'.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train The Fruit Segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imdb import FruitIMDB\n",
    "\n",
    "# # args\n",
    "# args.dataset_dir = 'datasets/fruit'\n",
    "# args.weights_dir = 'weights/fruit_baseline'\n",
    "# args.n_classes = 4\n",
    "# args.batch_size = 64\n",
    "# # print args\n",
    "# cmd_printer.divider(text=\"Hyper-parameters\", line_max=60)\n",
    "# for arg in vars(args):\n",
    "#     print(f\"   {arg}: {getattr(args, arg)}\")\n",
    "# cmd_printer.divider(line_max=60)\n",
    "\n",
    "\n",
    "# train_loader = DataLoader(dataset=FruitIMDB(args.dataset_dir, mode='train'),\n",
    "#                           batch_size=args.batch_size, shuffle=True,\n",
    "#                           num_workers=4, drop_last=True)\n",
    "\n",
    "# eval_loader = DataLoader(dataset=FruitIMDB(args.dataset_dir, mode='eval'),\n",
    "#                          batch_size=args.batch_size, shuffle=False,\n",
    "#                          num_workers=4, drop_last=False)\n",
    "\n",
    "# if args.model == 'res18_baseline':\n",
    "#     model = Res18Baseline(args)\n",
    "# elif args.model == 'res18_skip':\n",
    "#     model = Res18Skip(args)\n",
    "# trainer = Trainer(args)\n",
    "# trainer.fit(model, train_loader, eval_loader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6bca7b956aba6ad70b81e5790d180355329715e62b4bdc0f2e18c537f42a8c7e"
  },
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('rvss21': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
