{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxQZ_jVgEfrE"
      },
      "source": [
        "## Config CoLab Environment\n",
        "\n",
        "Make sure this script is opened from your own google drive folder, rather than directly opened from Github. This is crucial for saving your code for later use during the workshop. If you have not done it,  uncomment and run the cell below to clone the RVSS 2022 Github to your Google Drive, quit this Colab session and reopen it from your own google drive https://drive.google.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxX0bWmWEfrG"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# %cd / content/drive/MyDrive/\n",
        "# if not os.path.exists('RVSS2022'):\n",
        "#   !git clone https://github.com/Tobias-Fischer/RVSS2022\n",
        "# else:\n",
        "#   %cd / content/drive/MyDrive/RVSS2022\n",
        "#   !git pull\n",
        "# %cd / content/drive/MyDrive/RVSS2022/Visual_Learning/segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wSn8AtOEfrH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/RVSS2022/Visual_Learning/segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eynNB9IYEfrH"
      },
      "source": [
        "## Train The Networks\n",
        "Make sure the Runtime is selected as GPU accelerated. \n",
        "\n",
        "__Runtime can be changed from the menu:__\n",
        "_Runtime --> change runtime type --> Hardware accelerator --> GPU_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdGZ09a_EfrI"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from segmenter import Segmenter\n",
        "import utils.cmd_printer as cmd_printer\n",
        "from trainer import Trainer\n",
        "from args import args\n",
        "from models import Res18Baseline\n",
        "from models import Res18Skip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI3JmcdLEfrI"
      },
      "source": [
        "## Train The Face Segmentation\n",
        "\n",
        "The hyper-parameters are defaulted as:\n",
        "\n",
        "\n",
        "| Hyper-parameter | Describtion | Default Value |\n",
        "| :-: | :-: | :-: |\n",
        "|n_classes| the number of classes (background excluded)| - |\n",
        "|lr| learning rate | 1e-3 |\n",
        "|epochs| The number of training epochs | 10 |\n",
        "|batch_size| Batch size | 16 |\n",
        "|weight_decay| - | 1e-4 |\n",
        "|scheduler_step| Learning rate decays every X epochs | 5 |\n",
        "|scheduler_gamma| Learning rate decays to X*current_lr | 0.5 |\n",
        "|weights_dir| Path for saving trained weights | - |\n",
        "|model| Networ architectures, <br> choose between res18_baseline or res18_skip|res18_baseline|\n",
        "|dataset_dir| Path to the training dataset|-|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZJ0hIJmEfrI"
      },
      "outputs": [],
      "source": [
        "from imdb import FaceIMDB\n",
        "\n",
        "# args\n",
        "args.dataset_dir = 'datasets/faces'\n",
        "args.weights_dir = 'weights/face_baseline'\n",
        "args.n_classes = 2\n",
        "args.batch_size = 32\n",
        "# print args\n",
        "cmd_printer.divider(text=\"Hyper-parameters\", line_max=60)\n",
        "for arg in vars(args):\n",
        "    print(f\"   {arg}: {getattr(args, arg)}\")\n",
        "cmd_printer.divider(line_max=60)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=FaceIMDB(args.dataset_dir, mode='train'),\n",
        "                          batch_size=args.batch_size, shuffle=True,\n",
        "                          num_workers=4, drop_last=True)\n",
        "\n",
        "eval_loader = DataLoader(dataset=FaceIMDB(args.dataset_dir, mode='eval'),\n",
        "                         batch_size=args.batch_size, shuffle=False,\n",
        "                         num_workers=4, drop_last=False)\n",
        "   \n",
        "if args.model == 'res18_baseline':\n",
        "    model = Res18Baseline(args)\n",
        "elif args.model == 'res18_skip':\n",
        "    model = Res18Skip(args)\n",
        "trainer = Trainer(args)\n",
        "trainer.fit(model, train_loader, eval_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MApmiBGjEfrI"
      },
      "source": [
        "## Visualise Face Segmentation\n",
        "### 'ckpt' represents checkpoint.\n",
        "\n",
        "You can set `ckpt = ''` to test if your network architecture is implemented correctly.\n",
        "\n",
        "Later on, you can set `ckpt = <path_to_weight_file>` to inspect the network outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dBs8-4hEfrJ"
      },
      "outputs": [],
      "source": [
        "# ckpt = ''\n",
        "ckpt = 'weights/face_baseline/model.best.pth'\n",
        "model = 'res18_baseline'\n",
        "# ckpt = 'res18_skip_weights.pth'\n",
        "# model = 'res18_skip'\n",
        "segmenter = Segmenter(ckpt, use_gpu=False, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaSFddLCEfrJ"
      },
      "outputs": [],
      "source": [
        "test_dir = \"test_images/faces\"\n",
        "pred_dir = os.path.join(test_dir, model+'_output')\n",
        "os.makedirs(pred_dir, exist_ok=True)\n",
        "all_test_images = [file for file in os.listdir(\n",
        "    test_dir) if file.endswith('.jpg')]\n",
        "for image_name in all_test_images:\n",
        "    np_img = np.array(Image.open(os.path.join(test_dir, image_name)))\n",
        "    pred, colour_map = segmenter.segment_single_image(\n",
        "        np_img, resize_to=(256, 256), labels=['hair', 'face', 'bg'])\n",
        "    title = [\"Input\", \"Prediction\"]\n",
        "    pics = [np_img, colour_map]\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
        "    axs[0].imshow(pics[0], interpolation='nearest')\n",
        "    axs[0].set_title(title[0])\n",
        "    axs[1].imshow(pics[1], interpolation='nearest')\n",
        "    axs[1].set_title(title[1])\n",
        "    axs[0].axis('off')\n",
        "    axs[1].axis('off')\n",
        "    path = os.path.join(pred_dir, image_name)\n",
        "    plt.savefig(os.path.join(pred_dir, image_name[:-4]+'.jpg'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yOJEPMdEfrJ"
      },
      "source": [
        "## Train The Fruit Segmentation Model\n",
        "\n",
        "| Hyper-parameter | Describtion | Default Value |\n",
        "| :-: | :-: | :-: |\n",
        "|n_classes| the number of classes (background excluded)| - |\n",
        "|lr| learning rate | 1e-3 |\n",
        "|epochs| The number of training epochs | 10 |\n",
        "|batch_size| Batch size | 16 |\n",
        "|weight_decay| - | 1e-4 |\n",
        "|scheduler_step| Learning rate decays every X epochs | 5 |\n",
        "|scheduler_gamma| Learning rate decays to X*current_lr | 0.5 |\n",
        "|weights_dir| Path for saving trained weights | - |\n",
        "|model| Networ architectures, <br> choose between res18_baseline or res18_skip|res18_baseline|\n",
        "|dataset_dir| Path to the training dataset|-|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wW4ZsaxOEfrJ"
      },
      "outputs": [],
      "source": [
        "# from imdb import FruitIMDB\n",
        "\n",
        "# # args\n",
        "# args.dataset_dir = 'datasets/fruit'\n",
        "# args.weights_dir = 'weights/fruit_baseline'\n",
        "# args.n_classes = 4\n",
        "# args.batch_size = 64\n",
        "# # print args\n",
        "# cmd_printer.divider(text=\"Hyper-parameters\", line_max=60)\n",
        "# for arg in vars(args):\n",
        "#     print(f\"   {arg}: {getattr(args, arg)}\")\n",
        "# cmd_printer.divider(line_max=60)\n",
        "\n",
        "\n",
        "# train_loader = DataLoader(dataset=FruitIMDB(args.dataset_dir, mode='train'),\n",
        "#                           batch_size=args.batch_size, shuffle=True,\n",
        "#                           num_workers=4, drop_last=True)\n",
        "\n",
        "# eval_loader = DataLoader(dataset=FruitIMDB(args.dataset_dir, mode='eval'),\n",
        "#                          batch_size=args.batch_size, shuffle=False,\n",
        "#                          num_workers=4, drop_last=False)\n",
        "\n",
        "# if args.model == 'res18_baseline':\n",
        "#     model = Res18Baseline(args)\n",
        "# elif args.model == 'res18_skip':\n",
        "#     model = Res18Skip(args)\n",
        "# trainer = Trainer(args)\n",
        "# trainer.fit(model, train_loader, eval_loader)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "6bca7b956aba6ad70b81e5790d180355329715e62b4bdc0f2e18c537f42a8c7e"
    },
    "kernelspec": {
      "display_name": "Python 3.6.12 64-bit ('rvss21': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "orig_nbformat": 2,
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}