{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification with Convolutional NN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the packages required.\n",
    "\n",
    "**Note**: Select ***conda_pytorch_p36*** as the kernel for this notebook if running on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import time for timekeeping\n",
    "import time\n",
    "# io allows reading and writing image from disk\n",
    "# from skimage import io\n",
    "\n",
    "\n",
    "# Pytorch (Our Deep Learning Framework)\n",
    "import torch\n",
    "\n",
    "# Torch Data Loader (this will be helful to load image)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# datasets have mnist if using coustom images import io from skimage\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "# stores different optimizors like SGD\n",
    "import torch.optim as optim\n",
    "\n",
    "# Some torch functions that are used multiple times\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "# Set to True if using ml.p2.xlarge Instances\n",
    "FLAG_GPU = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the Multi Layer Perceptron definition you saw.\n",
    "* Any network has an * __ init __ * function that initializes all the layers on a NN that require learnable parameters.\n",
    "* A MPL is stack of fully connected layers. In this example we use three fully connected layers named :''fc0'', ''fc1'' and ''fc2''.\n",
    "* Note that each fully connected layer has a number of input neurons that connect to a number of output neurons. \n",
    "* These input and output dimenssions are specified in fc layers initialization.\n",
    "* If a fully connected layers connect to another, its output size = input size of fully connected layer that followes.\n",
    "* Number of paramenters in any fully connected layer is #Input x #Output (and 1 bias per output).\n",
    "\n",
    "## How do we write a forward function?\n",
    "* torch.flatten(x, start_dim = dim) converts an image like entity to a vector.\n",
    "* Remeber that you need activations after every fc layer. In this case ReLu. \n",
    "* Notice the log_sofmax layer at the end. This is a softmax activation function followed by log function as name suggests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        \n",
    "        # First fully connected layers input image is 28x28 = 784 dim.\n",
    "        self.fc0 = nn.Linear(784, 256) # nparam = 784*256 = 38400\n",
    "        # Two more fully connected layers\n",
    "        self.fc1 = nn.Linear(256, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flattens the image like structure into vectors\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        # fully connected layers with activations\n",
    "        x = self.fc0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # Outputs are log(p) so softmax followed by log.\n",
    "        #return(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our task today is to replace this with a convolutional NN.\n",
    "\n",
    "## The Lecun Net we want to implement should look like the one in this figure:\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1200/1*1TI1aGBZ4dybR6__DI9dzA.png)\n",
    "\n",
    "* Our network now has two blocks, each of them has the structure 'convolution followed by relu followed by max pooling'.\n",
    "* These two blocks replace the 'fc0'+relu layer in the example MLP. \n",
    "* Read inline TODO comments to change the model convolution net ?for training.\n",
    "\n",
    "**Conv2d is 2D convolutional layer:**\n",
    "   * Initialization reqires the kernal/filter size, number of input channels and number of filters (defining size of output).\n",
    "   * First block has 5x5 convolutional filters. We use 6 of them. Convolutional layer takes a 28x28 image of one channel as input.\n",
    "   * *TODO* What do you think will be the number of parameters needed for adding this layer?\n",
    "   * What will be the size after the first 5x5 convolution? Why?\n",
    "   * Second convolution is again 5x5 but this time we use 16 filters as the data we want to encode is more complex.\n",
    "   * Remember to add activation after every convolution!\n",
    "    \n",
    "**MaxPooling2D does subsampling**\n",
    "   * y = F.max_pool2d(x, k) command is used to perform kxk max pooling of some data x to create a smaller y. \n",
    "   * If the input images to pooling are 2Mx2N, then you will get MxN size output.\n",
    "   * We will use 2x2 max pooling after every convolution-relu in this excersise.\n",
    "**We will keep the 'fc1' and 'fc2' from MLP as it is**\n",
    "\n",
    "# Your job here is to put conv-relu-pooling layers in appropriate order to write a forward function.\n",
    "* **Remember that torch.flatten() converts images to vectors, where will you put the flatten layer now?**\n",
    "* **Think about the number of parameters that you saved by replacing the fc0 of the MLP in this case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # Two convolution layers I am writing the first one\n",
    "        # First convolutional layer takes single chennel images (batch_size specify the number of images) as input\n",
    "        # We have 5x5 convolutions\n",
    "        # We have 6 convolutional filter to produce output size 6*28*28 for a single training sample.\n",
    "        # structure is : nn.conv2d(number of input channels, number of filters, conv kernel size, stride = 1)\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, 1)  \n",
    "        # Note that Nparam 1*6*5*5 = 150 (+ 5 for bias per output).\n",
    "        \n",
    "        #################################################################################\n",
    "        # TODO: add another layer called self.conv2, 5x5 convolutions 16 filters in total.\n",
    "        #################################################################################\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, 1)  \n",
    "\n",
    "        # Two more fully connected layers arguments (input size, output size)\n",
    "        self.fc1 = nn.Linear(256, 84)\n",
    "        #################################################################################\n",
    "        # TODO: what is the input and output sizes to fc2?\n",
    "        #################################################################################\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "        # 10 outputs are probability of any specefic digit present in the image\n",
    "        # All sum to one\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input goes to convolution so no need to flatten the image yet\n",
    "        #################################################################################\n",
    "        # TODO: add a 5x5 convolution block (conv1 followed by activation followed by 2x2 max pooling)\n",
    "        #################################################################################\n",
    "        # use conv1 output = self.conv1(input)\n",
    "        # use relu as activation with syntext: output = F.relu(input)\n",
    "        # use max pooling with syntext:  output = F.max_pool2d(input, pooling kernal size)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        \n",
    "        \n",
    "        #################################################################################\n",
    "        # TODO: add aother 5x5 convolution block (conv2 followed by activation followed by max pooling)  \n",
    "        #################################################################################\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Think what will be the size now of the image now \n",
    "        # if you don't pad images it is actually (4x4x16)\n",
    "       \n",
    "        #################################################################################\n",
    "        # TODO: following upon your understanding regarding the size of the output, \n",
    "        # do you need to adjust the forward function in any way?\n",
    "        #################################################################################\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        # fully connected layers these remains as is\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # return(x)\n",
    "        # Outputs are log(p)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The rest of the code to train can be used as it is.\n",
    "# We initialize the instance of ConvNet insted of MLP and train it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing a instance of the defined network here.\n",
    "* Note that puting a network to GPU is as simple as writing .cuda() at the end of the instance.\n",
    "* Same is true for a variable. In this  notebook the code inside command \"if FLAG_GPU\" shows all the modifications you need to run your code on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNet()\n",
    "if FLAG_GPU:\n",
    "    net.cuda()\n",
    "    print(net)\n",
    "else:\n",
    "    print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders and Transforms.\n",
    "* dataset.MNIST in pytorch has functionality to download and process MNIST data.\n",
    "* dataloader function usually allows for loading parts of training and test data in minibatches.\n",
    "* It can use somple simple transformations implemented in class transforms that assists training. For example normalizing, resizing or cropping images.\n",
    "* Functionality to dataset, transforms and dataloader classes are usually added to suit new data and training proceedure related to the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Training dataset and training loader.\n",
    "trainset = datasets.MNIST(root='../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "# Test dataset and loader.\n",
    "testset = datasets.MNIST(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we see sample usage of loading some MNIST training data.\n",
    "* How does out training minibatch looks?\n",
    "* At times simple visualization and print statements allowes for understanding/debugging effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, l):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    print('Labels were:')\n",
    "    print(l.reshape(-1,8).numpy())\n",
    "\n",
    "# Load sample data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print('shape of images', images.shape)\n",
    "\n",
    "# display batch\n",
    "imshow(utils.make_grid(images),labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function for learning.\n",
    "* NLLLoss: The abbrivation NLL stands for Negetive log likelihood. It is however a bit of misnomer as the log is not included in the loss itself but was part of the network defination above. \n",
    "* NOTE: When you want to get the probability/likelihood of an image being of a perticular class you need to remove the log from the forward function and use simple softmax activation at test time. Alternatively simply use ''exp'' function from torch to invert log and leave the forward function as it is. \n",
    "\n",
    "## Optimizer\n",
    "* pytorch have various optimization rutines (beyond SGD) pre-implemented.\n",
    "* class optim will take care of backpropogation with these different optimizations for learning as long as the network defination with appropriate forward function is written correctly.\n",
    "* Here we just use SGD. with learning rate 0.001 and momentum 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "if FLAG_GPU:\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This cell of the notebook is now training a network.\n",
    "\n",
    "* First for loop goes throught the entire data 5 times (We run 5 epochs for our training).\n",
    "* The simple steps for training a NN with pytorch are:\n",
    "    * Load data in minibatches.\n",
    "    * Set gradients for all the network parameters to zero (dont forget this)\n",
    "    * Pass data to the NN using a net.forward() to compute layer by layer output.\n",
    "        * Intermediate outputs can be returned as extra variables in forward function.\n",
    "    * Compute the loss from the output (remember it is defined above).\n",
    "    * Use loss.backword() to compute all the gradients by appropriately applying chain rule! \n",
    "        * It actually know how to differentiate things!!!\n",
    "    * Use optimizer.step() updates weights.\n",
    "    \n",
    "## At the end of every epoch usually we check if NN generalizes.\n",
    "* Generalization is critical in learning.\n",
    "* We evaluate the performance of our NN on new data, for which the NN loss was not minimized.\n",
    "* torch.no_grad() command forces the following code to not keep track of the gradients as for testing we dont need them.\n",
    "* As no gradients are maintained, the code runs faster!\n",
    "* It a very good practice to make use of no_grad function to ensure that we dont accidently minimize loss on the data we are testing the performance on.\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Simply for time keeping\n",
    "    start_time = time.time()\n",
    "    # Loop over all training data\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    " \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward \n",
    "        if FLAG_GPU:\n",
    "            outputs = net(inputs.cuda())\n",
    "            loss = criterion(outputs, labels.cuda())\n",
    "        else:\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Compute Gradients\n",
    "        loss.backward()\n",
    "        # BackProp\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "        # endif\n",
    "    # end for over minibatches epoch finishes\n",
    "    end_time = time.time()\n",
    "\n",
    "    # test the network every epoch on test example\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Test after the epoch finishes (no gradient computation needed)\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            # load images and labels\n",
    "            images, labels = data\n",
    "\n",
    "            if FLAG_GPU:\n",
    "                outputs = net(images.cuda())\n",
    "                # note here we take the max of all probability\n",
    "                _, predicted = torch.max(outputs.cpu(), 1)\n",
    "            else:\n",
    "                outputs = net(images)\n",
    "                # note here we take the max of all probability\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "         #end for\n",
    "    #end with\n",
    "    print('Epoch', epoch+1, 'took', end_time-start_time, 'seconds')\n",
    "    print('Accuracy of the network after', epoch+1, 'epochs is' , 100*correct/total)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
